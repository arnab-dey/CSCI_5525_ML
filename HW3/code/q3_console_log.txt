###### Running part 1: SGD with batch size 32 ######
Epoch:  1 , loss =  0.5302433967590332 , accuracy =  0.8320666551589966
Epoch:  2 , loss =  0.26935383677482605 , accuracy =  0.9169999957084656
Epoch:  3 , loss =  0.21418555080890656 , accuracy =  0.9350500106811523
Epoch:  4 , loss =  0.183950737118721 , accuracy =  0.943316638469696
Epoch:  5 , loss =  0.16930250823497772 , accuracy =  0.9482499957084656
Epoch:  6 , loss =  0.15841835737228394 , accuracy =  0.9509833455085754
Epoch:  7 , loss =  0.1445639431476593 , accuracy =  0.9556166529655457
Epoch:  8 , loss =  0.13766475021839142 , accuracy =  0.9577333331108093
Epoch:  9 , loss =  0.1314173936843872 , accuracy =  0.9595333337783813
Epoch:  10 , loss =  0.12572215497493744 , accuracy =  0.9617833495140076
Epoch:  11 , loss =  0.12158559262752533 , accuracy =  0.9629833102226257
Epoch:  12 , loss =  0.116225965321064 , accuracy =  0.963866651058197
Epoch:  13 , loss =  0.10962548851966858 , accuracy =  0.9663333296775818
Epoch:  14 , loss =  0.10982366651296616 , accuracy =  0.9664000272750854
Epoch:  15 , loss =  0.10488145053386688 , accuracy =  0.9675166606903076
Epoch:  16 , loss =  0.10131342709064484 , accuracy =  0.9678833484649658
Epoch:  17 , loss =  0.10150513052940369 , accuracy =  0.968666672706604
Epoch:  18 , loss =  0.09612277895212173 , accuracy =  0.9698166847229004
Epoch:  19 , loss =  0.09466484934091568 , accuracy =  0.9709500074386597
Epoch:  20 , loss =  0.09340173006057739 , accuracy =  0.9709333181381226
Epoch:  21 , loss =  0.09092942625284195 , accuracy =  0.9714000225067139
Epoch:  22 , loss =  0.08625756204128265 , accuracy =  0.9729833602905273
Epoch:  23 , loss =  0.08644556254148483 , accuracy =  0.9727500081062317
Epoch:  24 , loss =  0.08592518419027328 , accuracy =  0.9731000065803528
Epoch:  25 , loss =  0.08350130915641785 , accuracy =  0.9741666913032532
Epoch:  26 , loss =  0.08164054900407791 , accuracy =  0.9745333194732666
Epoch:  27 , loss =  0.08000974357128143 , accuracy =  0.9746500253677368
Epoch:  28 , loss =  0.07932419329881668 , accuracy =  0.9750000238418579
Epoch:  29 , loss =  0.07834785431623459 , accuracy =  0.9754666686058044
Epoch:  30 , loss =  0.07754118740558624 , accuracy =  0.975600004196167
test loss =  0.03535482659935951 , test accuracy =  0.9882000088691711
###### Running part 2: SGD with batch size  32  ######
Epoch:  1 , loss =  0.5277223587036133 , accuracy =  0.8327999711036682
Epoch:  2 , loss =  0.265020489692688 , accuracy =  0.9186000227928162
Epoch:  3 , loss =  0.20578186213970184 , accuracy =  0.9376000165939331
Epoch:  4 , loss =  0.17528453469276428 , accuracy =  0.9466833472251892
Epoch:  5 , loss =  0.15702536702156067 , accuracy =  0.9512333273887634
Epoch:  6 , loss =  0.14460106194019318 , accuracy =  0.9559333324432373
Epoch:  7 , loss =  0.13529779016971588 , accuracy =  0.9585166573524475
Epoch:  8 , loss =  0.1292973756790161 , accuracy =  0.9605500102043152
Epoch:  9 , loss =  0.12018539011478424 , accuracy =  0.9630333185195923
Epoch:  10 , loss =  0.11211144924163818 , accuracy =  0.9657999873161316
Epoch:  11 , loss =  0.10842642188072205 , accuracy =  0.96670001745224
Epoch:  12 , loss =  0.10658823698759079 , accuracy =  0.9670000076293945
Epoch:  13 , loss =  0.10123815387487411 , accuracy =  0.9692166447639465
Epoch:  14 , loss =  0.09776213020086288 , accuracy =  0.9699000120162964
Epoch:  15 , loss =  0.09524086862802505 , accuracy =  0.9699833393096924
Epoch:  16 , loss =  0.08992542326450348 , accuracy =  0.971916675567627
Epoch:  17 , loss =  0.09114404022693634 , accuracy =  0.9715499877929688
Epoch:  18 , loss =  0.08985157310962677 , accuracy =  0.9717333316802979
Epoch:  19 , loss =  0.08595307171344757 , accuracy =  0.9732000231742859
Epoch:  20 , loss =  0.08268070966005325 , accuracy =  0.9743833541870117
Epoch:  21 , loss =  0.08132598549127579 , accuracy =  0.9747666716575623
Epoch:  22 , loss =  0.0810660794377327 , accuracy =  0.9750666618347168
Epoch:  23 , loss =  0.07659322768449783 , accuracy =  0.9757333397865295
Epoch:  24 , loss =  0.07652909308671951 , accuracy =  0.9769333600997925
Epoch:  25 , loss =  0.07641534507274628 , accuracy =  0.9766333103179932
Epoch:  26 , loss =  0.07366112619638443 , accuracy =  0.9775166511535645
Epoch:  27 , loss =  0.07405862957239151 , accuracy =  0.9767500162124634
Epoch:  28 , loss =  0.07168296724557877 , accuracy =  0.9771999716758728
Epoch:  29 , loss =  0.07163761556148529 , accuracy =  0.9776999950408936
Epoch:  30 , loss =  0.07012486457824707 , accuracy =  0.9782333374023438
Epoch:  31 , loss =  0.06973398476839066 , accuracy =  0.9781166911125183
Epoch:  32 , loss =  0.06575551629066467 , accuracy =  0.9792666435241699
Epoch:  33 , loss =  0.06786003708839417 , accuracy =  0.978950023651123
Epoch:  34 , loss =  0.0663280189037323 , accuracy =  0.9786999821662903
Epoch:  35 , loss =  0.06449935585260391 , accuracy =  0.9795500040054321
Epoch:  36 , loss =  0.06573429703712463 , accuracy =  0.9797499775886536
Epoch:  37 , loss =  0.0614827424287796 , accuracy =  0.9807000160217285
Epoch:  38 , loss =  0.061878565698862076 , accuracy =  0.9806833267211914
Epoch:  39 , loss =  0.06225202977657318 , accuracy =  0.9801999926567078
Epoch:  40 , loss =  0.06016659736633301 , accuracy =  0.9807833433151245
Epoch:  41 , loss =  0.060923174023628235 , accuracy =  0.9805833101272583
Epoch:  42 , loss =  0.061471227556467056 , accuracy =  0.980566680431366
Epoch:  43 , loss =  0.056688565760850906 , accuracy =  0.9819833040237427
Epoch:  44 , loss =  0.057608023285865784 , accuracy =  0.9818166494369507
Epoch:  45 , loss =  0.059494514018297195 , accuracy =  0.9808333516120911
Epoch:  46 , loss =  0.05691803619265556 , accuracy =  0.9817833304405212
SGD: batch size =  32  convergence time =  1635.2970943450928
SGD: batch size =  32 , test loss =  0.0317993089556694 , test accuracy =  0.9886999726295471
###### Running part 2: ADAGRAD with batch size  32  ######
Epoch:  1 , loss =  0.8973408937454224 , accuracy =  0.698283314704895
Epoch:  2 , loss =  0.29962900280952454 , accuracy =  0.9070166945457458
Epoch:  3 , loss =  0.23657740652561188 , accuracy =  0.9278166890144348
Epoch:  4 , loss =  0.20025098323822021 , accuracy =  0.9383833408355713
Epoch:  5 , loss =  0.18707183003425598 , accuracy =  0.942799985408783
Epoch:  6 , loss =  0.16990849375724792 , accuracy =  0.9474499821662903
Epoch:  7 , loss =  0.1609187126159668 , accuracy =  0.9511666893959045
Epoch:  8 , loss =  0.15389831364154816 , accuracy =  0.9530166387557983
Epoch:  9 , loss =  0.15029571950435638 , accuracy =  0.9538666605949402
Epoch:  10 , loss =  0.13949304819107056 , accuracy =  0.9570666551589966
Epoch:  11 , loss =  0.1377275288105011 , accuracy =  0.9574166536331177
Epoch:  12 , loss =  0.13495980203151703 , accuracy =  0.9591166377067566
Epoch:  13 , loss =  0.1309797167778015 , accuracy =  0.9590166807174683
Epoch:  14 , loss =  0.12767833471298218 , accuracy =  0.9608833193778992
Epoch:  15 , loss =  0.12558306753635406 , accuracy =  0.9615499973297119
Epoch:  16 , loss =  0.12103744596242905 , accuracy =  0.9625833630561829
Epoch:  17 , loss =  0.11846539378166199 , accuracy =  0.963533341884613
Epoch:  18 , loss =  0.11729211360216141 , accuracy =  0.963450014591217
Epoch:  19 , loss =  0.11225876212120056 , accuracy =  0.965583324432373
Epoch:  20 , loss =  0.11415940523147583 , accuracy =  0.9642999768257141
Epoch:  21 , loss =  0.11216442286968231 , accuracy =  0.965149998664856
Epoch:  22 , loss =  0.10688881576061249 , accuracy =  0.9665166735649109
Epoch:  23 , loss =  0.10537360608577728 , accuracy =  0.9674500226974487
Epoch:  24 , loss =  0.10285845398902893 , accuracy =  0.9676499962806702
Epoch:  25 , loss =  0.10232993215322495 , accuracy =  0.9674333333969116
Epoch:  26 , loss =  0.10278835147619247 , accuracy =  0.9683833122253418
Epoch:  27 , loss =  0.10226774960756302 , accuracy =  0.9674333333969116
Epoch:  28 , loss =  0.09991613775491714 , accuracy =  0.9686833620071411
Epoch:  29 , loss =  0.09635121375322342 , accuracy =  0.9708333611488342
Epoch:  30 , loss =  0.09263628721237183 , accuracy =  0.9702000021934509
Epoch:  31 , loss =  0.09644602239131927 , accuracy =  0.9701833128929138
Epoch:  32 , loss =  0.09557116776704788 , accuracy =  0.9699333310127258
Epoch:  33 , loss =  0.09660059958696365 , accuracy =  0.9698500037193298
ADAGRAD: batch size =  32  convergence time =  1202.7207462787628
ADAGRAD: batch size =  32 , test loss =  0.03939347714185715 , test accuracy =  0.9865999817848206
###### Running part 2: ADAM with batch size  32  ######
Epoch:  1 , loss =  0.4079868793487549 , accuracy =  0.8742833137512207
Epoch:  2 , loss =  0.19661282002925873 , accuracy =  0.9394833445549011
Epoch:  3 , loss =  0.15877999365329742 , accuracy =  0.9513499736785889
Epoch:  4 , loss =  0.13697238266468048 , accuracy =  0.9579333066940308
Epoch:  5 , loss =  0.1204218864440918 , accuracy =  0.9622666835784912
Epoch:  6 , loss =  0.11073771864175797 , accuracy =  0.9667333364486694
Epoch:  7 , loss =  0.10086902976036072 , accuracy =  0.9689333438873291
Epoch:  8 , loss =  0.09590619057416916 , accuracy =  0.9706500172615051
Epoch:  9 , loss =  0.0902991071343422 , accuracy =  0.972183346748352
Epoch:  10 , loss =  0.08423849195241928 , accuracy =  0.973466694355011
Epoch:  11 , loss =  0.0835954025387764 , accuracy =  0.9746166467666626
Epoch:  12 , loss =  0.07922884821891785 , accuracy =  0.975433349609375
Epoch:  13 , loss =  0.07458928227424622 , accuracy =  0.9767500162124634
Epoch:  14 , loss =  0.07412289083003998 , accuracy =  0.9770833253860474
Epoch:  15 , loss =  0.06712557375431061 , accuracy =  0.9789000153541565
Epoch:  16 , loss =  0.06732463091611862 , accuracy =  0.979033350944519
Epoch:  17 , loss =  0.06942678242921829 , accuracy =  0.9782999753952026
Epoch:  18 , loss =  0.06655500084161758 , accuracy =  0.9789999723434448
Epoch:  19 , loss =  0.0652177557349205 , accuracy =  0.9797666668891907
Epoch:  20 , loss =  0.062174178659915924 , accuracy =  0.9799166917800903
Epoch:  21 , loss =  0.062055233865976334 , accuracy =  0.9801666736602783
Epoch:  22 , loss =  0.06025410443544388 , accuracy =  0.980650007724762
Epoch:  23 , loss =  0.05831374600529671 , accuracy =  0.9822499752044678
Epoch:  24 , loss =  0.060638874769210815 , accuracy =  0.9801833629608154
Epoch:  25 , loss =  0.05717222020030022 , accuracy =  0.9819833040237427
Epoch:  26 , loss =  0.05767715349793434 , accuracy =  0.9824833273887634
Epoch:  27 , loss =  0.05313420668244362 , accuracy =  0.9832333326339722
Epoch:  28 , loss =  0.05604800209403038 , accuracy =  0.9822999835014343
Epoch:  29 , loss =  0.05453232675790787 , accuracy =  0.982366681098938
Epoch:  30 , loss =  0.05383569374680519 , accuracy =  0.9829666614532471
ADAM: batch size =  32  convergence time =  1106.740294456482
ADAM: batch size =  32 , test loss =  0.03921477496623993 , test accuracy =  0.9883000254631042
###### Running part 2: SGD with batch size  64  ######
Epoch:  1 , loss =  0.05802983045578003 , accuracy =  0.9815666675567627
Epoch:  2 , loss =  0.05679274722933769 , accuracy =  0.9820500016212463
Epoch:  3 , loss =  0.0537114180624485 , accuracy =  0.98253333568573
Epoch:  4 , loss =  0.05477786064147949 , accuracy =  0.9825999736785889
Epoch:  5 , loss =  0.053401775658130646 , accuracy =  0.982366681098938
Epoch:  6 , loss =  0.054078422486782074 , accuracy =  0.9828333258628845
Epoch:  7 , loss =  0.05224695801734924 , accuracy =  0.9829833507537842
Epoch:  8 , loss =  0.050950560718774796 , accuracy =  0.9841333627700806
Epoch:  9 , loss =  0.05279156193137169 , accuracy =  0.9833333492279053
Epoch:  10 , loss =  0.05374079570174217 , accuracy =  0.9828500151634216
Epoch:  11 , loss =  0.05071341618895531 , accuracy =  0.9840499758720398
Epoch:  12 , loss =  0.05114941671490669 , accuracy =  0.9838333129882812
Epoch:  13 , loss =  0.05223818123340607 , accuracy =  0.9829666614532471
Epoch:  14 , loss =  0.05185363069176674 , accuracy =  0.9833333492279053
SGD: batch size =  64  convergence time =  475.65537452697754
SGD: batch size =  64 , test loss =  0.030407043173909187 , test accuracy =  0.989799976348877
###### Running part 2: ADAGRAD with batch size  64  ######
Epoch:  1 , loss =  0.09424710273742676 , accuracy =  0.9707000255584717
Epoch:  2 , loss =  0.0935688465833664 , accuracy =  0.9712333083152771
Epoch:  3 , loss =  0.09291480481624603 , accuracy =  0.9700999855995178
Epoch:  4 , loss =  0.08878675848245621 , accuracy =  0.9714499711990356
Epoch:  5 , loss =  0.089071124792099 , accuracy =  0.9715999960899353
Epoch:  6 , loss =  0.0888962596654892 , accuracy =  0.9722166657447815
Epoch:  7 , loss =  0.08758566528558731 , accuracy =  0.9729999899864197
Epoch:  8 , loss =  0.09073957055807114 , accuracy =  0.9713333249092102
Epoch:  9 , loss =  0.08767928183078766 , accuracy =  0.9721666574478149
Epoch:  10 , loss =  0.08830148726701736 , accuracy =  0.9720666408538818
ADAGRAD: batch size =  64  convergence time =  343.998761177063
ADAGRAD: batch size =  64 , test loss =  0.039097923785448074 , test accuracy =  0.9868999719619751
###### Running part 2: ADAM with batch size  64  ######
Epoch:  1 , loss =  0.05125939100980759 , accuracy =  0.984083354473114
Epoch:  2 , loss =  0.049100544303655624 , accuracy =  0.9841333627700806
Epoch:  3 , loss =  0.049269482493400574 , accuracy =  0.984333336353302
Epoch:  4 , loss =  0.04703333228826523 , accuracy =  0.9848333597183228
Epoch:  5 , loss =  0.04559709504246712 , accuracy =  0.9851499795913696
Epoch:  6 , loss =  0.044477906078100204 , accuracy =  0.9859333038330078
Epoch:  7 , loss =  0.04729551449418068 , accuracy =  0.9850500226020813
Epoch:  8 , loss =  0.0474533773958683 , accuracy =  0.9847000241279602
Epoch:  9 , loss =  0.043960705399513245 , accuracy =  0.9857000112533569
Epoch:  10 , loss =  0.0440714992582798 , accuracy =  0.98580002784729
Epoch:  11 , loss =  0.04402964562177658 , accuracy =  0.9855833053588867
Epoch:  12 , loss =  0.046188000589609146 , accuracy =  0.9854999780654907
ADAM: batch size =  64  convergence time =  417.629665851593
ADAM: batch size =  64 , test loss =  0.036263883113861084 , test accuracy =  0.9902999997138977
###### Running part 2: SGD with batch size  96  ######
Epoch:  1 , loss =  0.05287862569093704 , accuracy =  0.9829666614532471
Epoch:  2 , loss =  0.05015973374247551 , accuracy =  0.984250009059906
Epoch:  3 , loss =  0.049874577671289444 , accuracy =  0.9840166568756104
Epoch:  4 , loss =  0.048951487988233566 , accuracy =  0.9838333129882812
Epoch:  5 , loss =  0.04959239438176155 , accuracy =  0.9837666749954224
Epoch:  6 , loss =  0.04950454831123352 , accuracy =  0.9842166900634766
Epoch:  7 , loss =  0.04938828572630882 , accuracy =  0.9846500158309937
SGD: batch size =  96  convergence time =  239.79189801216125
SGD: batch size =  96 , test loss =  0.03122592531144619 , test accuracy =  0.989799976348877
###### Running part 2: ADAGRAD with batch size  96  ######
Epoch:  1 , loss =  0.0874667689204216 , accuracy =  0.972516655921936
Epoch:  2 , loss =  0.08731886744499207 , accuracy =  0.9721500277519226
Epoch:  3 , loss =  0.08596475422382355 , accuracy =  0.9730666875839233
Epoch:  4 , loss =  0.08593758195638657 , accuracy =  0.9727166891098022
Epoch:  5 , loss =  0.08507337421178818 , accuracy =  0.9731166958808899
Epoch:  6 , loss =  0.0844896212220192 , accuracy =  0.9735166430473328
ADAGRAD: batch size =  96  convergence time =  207.10378408432007
ADAGRAD: batch size =  96 , test loss =  0.03842497989535332 , test accuracy =  0.9876000285148621
###### Running part 2: ADAM with batch size  96  ######
Epoch:  1 , loss =  0.04310726746916771 , accuracy =  0.9864500164985657
Epoch:  2 , loss =  0.04275435209274292 , accuracy =  0.986133337020874
Epoch:  3 , loss =  0.03984446078538895 , accuracy =  0.9872499704360962
Epoch:  4 , loss =  0.040520455688238144 , accuracy =  0.9866999983787537
Epoch:  5 , loss =  0.041579488664865494 , accuracy =  0.9862333536148071
Epoch:  6 , loss =  0.03957756236195564 , accuracy =  0.9872333407402039
Epoch:  7 , loss =  0.04077986255288124 , accuracy =  0.9866499900817871
Epoch:  8 , loss =  0.04131238907575607 , accuracy =  0.9868500232696533
Epoch:  9 , loss =  0.03871240094304085 , accuracy =  0.987416684627533
Epoch:  10 , loss =  0.03981805592775345 , accuracy =  0.9870833158493042
Epoch:  11 , loss =  0.03925483301281929 , accuracy =  0.9875333309173584
Epoch:  12 , loss =  0.03832361102104187 , accuracy =  0.9876833558082581
ADAM: batch size =  96  convergence time =  415.30689311027527
ADAM: batch size =  96 , test loss =  0.03756103664636612 , test accuracy =  0.9907000064849854
###### Running part 2: SGD with batch size  128  ######
Epoch:  1 , loss =  0.04737330228090286 , accuracy =  0.9850500226020813
Epoch:  2 , loss =  0.04874235391616821 , accuracy =  0.984083354473114
Epoch:  3 , loss =  0.04891955479979515 , accuracy =  0.9842666387557983
Epoch:  4 , loss =  0.0488874725997448 , accuracy =  0.984000027179718
SGD: batch size =  128  convergence time =  136.7542462348938
SGD: batch size =  128 , test loss =  0.030153924599289894 , test accuracy =  0.9902999997138977
###### Running part 2: ADAGRAD with batch size  128  ######
Epoch:  1 , loss =  0.08472002297639847 , accuracy =  0.9728500247001648
Epoch:  2 , loss =  0.08630459010601044 , accuracy =  0.9723833203315735
Epoch:  3 , loss =  0.08594124019145966 , accuracy =  0.9731500148773193
Epoch:  4 , loss =  0.0846373662352562 , accuracy =  0.9733333587646484
Epoch:  5 , loss =  0.08681585639715195 , accuracy =  0.9729333519935608
Epoch:  6 , loss =  0.08397623896598816 , accuracy =  0.9735333323478699
Epoch:  7 , loss =  0.08580552786588669 , accuracy =  0.9732000231742859
Epoch:  8 , loss =  0.08507055044174194 , accuracy =  0.9726999998092651
Epoch:  9 , loss =  0.08061181753873825 , accuracy =  0.9747166633605957
Epoch:  10 , loss =  0.0837758332490921 , accuracy =  0.9730166792869568
Epoch:  11 , loss =  0.0832633376121521 , accuracy =  0.9737833142280579
Epoch:  12 , loss =  0.08201085031032562 , accuracy =  0.9733499884605408
ADAGRAD: batch size =  128  convergence time =  411.6216239929199
ADAGRAD: batch size =  128 , test loss =  0.03778873011469841 , test accuracy =  0.988099992275238
###### Running part 2: ADAM with batch size  128  ######
Epoch:  1 , loss =  0.037443820387125015 , accuracy =  0.9879999756813049
Epoch:  2 , loss =  0.037149231880903244 , accuracy =  0.9876333475112915
Epoch:  3 , loss =  0.03439973667263985 , accuracy =  0.989300012588501
Epoch:  4 , loss =  0.037112727761268616 , accuracy =  0.9879166483879089
Epoch:  5 , loss =  0.03586479648947716 , accuracy =  0.98826664686203
Epoch:  6 , loss =  0.0346156507730484 , accuracy =  0.98826664686203
ADAM: batch size =  128  convergence time =  212.70265412330627
ADAM: batch size =  128 , test loss =  0.03495612367987633 , test accuracy =  0.9905999898910522